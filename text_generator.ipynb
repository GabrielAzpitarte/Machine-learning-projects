{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielAzpitarte/Machine-learning-projects/blob/main/text_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Les données"
      ],
      "metadata": {
        "id": "_05jLgp0RplU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Les imports"
      ],
      "metadata": {
        "id": "XnQqgZP7Rs7C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6ASDsfWQ7Bj"
      },
      "outputs": [],
      "source": [
        "# Les imports de base pour retrvailler l'IA\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On aura besoin de tensorflow\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "hu2sZE2-SFHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importer nos données\n",
        "chemin = 'LesMiserables.txt'"
      ],
      "metadata": {
        "id": "z2pWFNtySrAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lire notre fichier\n",
        "texte = open(chemin, 'r').read()"
      ],
      "metadata": {
        "id": "irHvm2dnS5_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nbre de caracteres dans mon texte (1 million commence a être bien pour entrainer son IA)\n",
        "len(texte)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-8XEz_RTGXN",
        "outputId": "9c2461c8-1098-449a-cc0f-6312e89c3d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2468231"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Un oeil au texte (les 500 premiers caracteres)\n",
        "texte[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "h8pFJadPU1_z",
        "outputId": "f46e4eb0-2f99-4962-8756-18bddbd0c4d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Chapitre I\\n\\nMonsieur Myriel\\n\\n\\nEn 1815, M. Charles-François-Bienvenu Myriel était évêque de Digne.\\nC'était un vieillard d'environ soixante-quinze ans; il occupait le siège\\nde Digne depuis 1806.\\n\\nQuoique ce détail ne touche en aucune manière au fond même de ce que\\nnous avons à raconter, il n'est peut-être pas inutile, ne fût-ce que\\npour être exact en tout, d'indiquer ici les bruits et les propos qui\\navaient couru sur son compte au moment où il était arrivé dans le\\ndiocèse. Vrai ou faux, ce qu'on d\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Si à la place on le print, on voit la structure du texte, espaces, sauts de lignes etc\n",
        "print(texte[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqKaMFwuVNE7",
        "outputId": "8f73167e-6a1d-434b-9dc9-eb917056ca1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chapitre I\n",
            "\n",
            "Monsieur Myriel\n",
            "\n",
            "\n",
            "En 1815, M. Charles-François-Bienvenu Myriel était évêque de Digne.\n",
            "C'était un vieillard d'environ soixante-quinze ans; il occupait le siège\n",
            "de Digne depuis 1806.\n",
            "\n",
            "Quoique ce détail ne touche en aucune manière au fond même de ce que\n",
            "nous avons à raconter, il n'est peut-être pas inutile, ne fût-ce que\n",
            "pour être exact en tout, d'indiquer ici les bruits et les propos qui\n",
            "avaient couru sur son compte au moment où il était arrivé dans le\n",
            "diocèse. Vrai ou faux, ce qu'on d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher un morceau de texte au hasard\n",
        "print(texte[12000:12500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ti1e6-0aVdoW",
        "outputId": "75750aa6-5181-4a8e-c943-25b31ecaab89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ement lui doit pour ses frais de\n",
            "carrosse en ville et de tournées dans le diocèse. Pour les évêques\n",
            "d'autrefois c'était l'usage.\n",
            "\n",
            "--Tiens! dit l'évêque, vous avez raison, madame Magloire.\n",
            "\n",
            "Il fit sa réclamation.\n",
            "\n",
            "Quelque temps après, le conseil général, prenant cette demande en\n",
            "considération, lui vota une somme annuelle de trois mille francs, sous\n",
            "cette rubrique: _Allocation à M. l'évêque pour frais de carrosse, frais\n",
            "de poste et frais de tournées pastorales_.\n",
            "\n",
            "Cela fit beaucoup crier la bourgeo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Les caracteres uniques"
      ],
      "metadata": {
        "id": "O9N_peOxV-F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir le texte en un set\n",
        "set(texte)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzjCSE6-WF33",
        "outputId": "78e05fc1-dbfe-4118-f86c-51c766fd8607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '\"',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " '_',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '«',\n",
              " '°',\n",
              " 'º',\n",
              " '»',\n",
              " 'À',\n",
              " 'Â',\n",
              " 'Ç',\n",
              " 'È',\n",
              " 'É',\n",
              " 'Ê',\n",
              " 'Ô',\n",
              " 'à',\n",
              " 'â',\n",
              " 'æ',\n",
              " 'ç',\n",
              " 'è',\n",
              " 'é',\n",
              " 'ê',\n",
              " 'ë',\n",
              " 'î',\n",
              " 'ï',\n",
              " 'ñ',\n",
              " 'ô',\n",
              " 'ö',\n",
              " 'ù',\n",
              " 'û',\n",
              " 'ü'}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trier ce set par ordre\n",
        "sorted(set(texte))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2RBUaljWWeN",
        "outputId": "1b9042ee-96ab-443e-f064-91567c57cdf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '\"',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " '_',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '«',\n",
              " '°',\n",
              " 'º',\n",
              " '»',\n",
              " 'À',\n",
              " 'Â',\n",
              " 'Ç',\n",
              " 'È',\n",
              " 'É',\n",
              " 'Ê',\n",
              " 'Ô',\n",
              " 'à',\n",
              " 'â',\n",
              " 'æ',\n",
              " 'ç',\n",
              " 'è',\n",
              " 'é',\n",
              " 'ê',\n",
              " 'ë',\n",
              " 'î',\n",
              " 'ï',\n",
              " 'ñ',\n",
              " 'ô',\n",
              " 'ö',\n",
              " 'ù',\n",
              " 'û',\n",
              " 'ü']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On stocke notre set dans une variable pour l'appeler plus facilement\n",
        "vocabulaire = sorted(set(texte))\n",
        "print(vocabulaire)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWhvPRrfXDKP",
        "outputId": "993a25f4-4383-43ff-f520-1b2602a59e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '«', '°', 'º', '»', 'À', 'Â', 'Ç', 'È', 'É', 'Ê', 'Ô', 'à', 'â', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'î', 'ï', 'ñ', 'ô', 'ö', 'ù', 'û', 'ü']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hs : ici vous auriez pu voir le nbre de caractere\n",
        "len(vocabulaire)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu6D5nKDXVmG",
        "outputId": "da40180d-0c8c-429a-bfa8-d4ab5d58c894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "105"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traitement du texte et vectorisation"
      ],
      "metadata": {
        "id": "3PZ70-4bX8o4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectoriser le texte et créer un dictionnaire d'encodage"
      ],
      "metadata": {
        "id": "rIKIp0mMYCo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# On boucle sur chaque pair (caractere / son numéro)\n",
        "for pair in enumerate(vocabulaire):\n",
        "  print(pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69kd2dT1YKBH",
        "outputId": "437f3f73-80e2-4dce-8fad-f9268af02f06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '\\n')\n",
            "(1, ' ')\n",
            "(2, '!')\n",
            "(3, '\"')\n",
            "(4, \"'\")\n",
            "(5, '(')\n",
            "(6, ')')\n",
            "(7, '*')\n",
            "(8, ',')\n",
            "(9, '-')\n",
            "(10, '.')\n",
            "(11, '/')\n",
            "(12, '0')\n",
            "(13, '1')\n",
            "(14, '2')\n",
            "(15, '3')\n",
            "(16, '4')\n",
            "(17, '5')\n",
            "(18, '6')\n",
            "(19, '7')\n",
            "(20, '8')\n",
            "(21, '9')\n",
            "(22, ':')\n",
            "(23, ';')\n",
            "(24, '?')\n",
            "(25, 'A')\n",
            "(26, 'B')\n",
            "(27, 'C')\n",
            "(28, 'D')\n",
            "(29, 'E')\n",
            "(30, 'F')\n",
            "(31, 'G')\n",
            "(32, 'H')\n",
            "(33, 'I')\n",
            "(34, 'J')\n",
            "(35, 'K')\n",
            "(36, 'L')\n",
            "(37, 'M')\n",
            "(38, 'N')\n",
            "(39, 'O')\n",
            "(40, 'P')\n",
            "(41, 'Q')\n",
            "(42, 'R')\n",
            "(43, 'S')\n",
            "(44, 'T')\n",
            "(45, 'U')\n",
            "(46, 'V')\n",
            "(47, 'W')\n",
            "(48, 'X')\n",
            "(49, 'Y')\n",
            "(50, 'Z')\n",
            "(51, '_')\n",
            "(52, 'a')\n",
            "(53, 'b')\n",
            "(54, 'c')\n",
            "(55, 'd')\n",
            "(56, 'e')\n",
            "(57, 'f')\n",
            "(58, 'g')\n",
            "(59, 'h')\n",
            "(60, 'i')\n",
            "(61, 'j')\n",
            "(62, 'k')\n",
            "(63, 'l')\n",
            "(64, 'm')\n",
            "(65, 'n')\n",
            "(66, 'o')\n",
            "(67, 'p')\n",
            "(68, 'q')\n",
            "(69, 'r')\n",
            "(70, 's')\n",
            "(71, 't')\n",
            "(72, 'u')\n",
            "(73, 'v')\n",
            "(74, 'w')\n",
            "(75, 'x')\n",
            "(76, 'y')\n",
            "(77, 'z')\n",
            "(78, '«')\n",
            "(79, '°')\n",
            "(80, 'º')\n",
            "(81, '»')\n",
            "(82, 'À')\n",
            "(83, 'Â')\n",
            "(84, 'Ç')\n",
            "(85, 'È')\n",
            "(86, 'É')\n",
            "(87, 'Ê')\n",
            "(88, 'Ô')\n",
            "(89, 'à')\n",
            "(90, 'â')\n",
            "(91, 'æ')\n",
            "(92, 'ç')\n",
            "(93, 'è')\n",
            "(94, 'é')\n",
            "(95, 'ê')\n",
            "(96, 'ë')\n",
            "(97, 'î')\n",
            "(98, 'ï')\n",
            "(99, 'ñ')\n",
            "(100, 'ô')\n",
            "(101, 'ö')\n",
            "(102, 'ù')\n",
            "(103, 'û')\n",
            "(104, 'ü')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On va utiliser cette logique pour générer un dictionnaire qui passe d'un caractère à un index"
      ],
      "metadata": {
        "id": "RvsPEmugZGHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "caractere_par_index = {caractere:index for index, caractere in enumerate(vocabulaire)}\n",
        "\n",
        "#J'affiche le résultat en colonne (pour l'avoir en ligne j'aurais mis print())\n",
        "caractere_par_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlycIBLyZNjw",
        "outputId": "c84586a3-e895-4af1-e624-6c41ef2e0765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " \"'\": 4,\n",
              " '(': 5,\n",
              " ')': 6,\n",
              " '*': 7,\n",
              " ',': 8,\n",
              " '-': 9,\n",
              " '.': 10,\n",
              " '/': 11,\n",
              " '0': 12,\n",
              " '1': 13,\n",
              " '2': 14,\n",
              " '3': 15,\n",
              " '4': 16,\n",
              " '5': 17,\n",
              " '6': 18,\n",
              " '7': 19,\n",
              " '8': 20,\n",
              " '9': 21,\n",
              " ':': 22,\n",
              " ';': 23,\n",
              " '?': 24,\n",
              " 'A': 25,\n",
              " 'B': 26,\n",
              " 'C': 27,\n",
              " 'D': 28,\n",
              " 'E': 29,\n",
              " 'F': 30,\n",
              " 'G': 31,\n",
              " 'H': 32,\n",
              " 'I': 33,\n",
              " 'J': 34,\n",
              " 'K': 35,\n",
              " 'L': 36,\n",
              " 'M': 37,\n",
              " 'N': 38,\n",
              " 'O': 39,\n",
              " 'P': 40,\n",
              " 'Q': 41,\n",
              " 'R': 42,\n",
              " 'S': 43,\n",
              " 'T': 44,\n",
              " 'U': 45,\n",
              " 'V': 46,\n",
              " 'W': 47,\n",
              " 'X': 48,\n",
              " 'Y': 49,\n",
              " 'Z': 50,\n",
              " '_': 51,\n",
              " 'a': 52,\n",
              " 'b': 53,\n",
              " 'c': 54,\n",
              " 'd': 55,\n",
              " 'e': 56,\n",
              " 'f': 57,\n",
              " 'g': 58,\n",
              " 'h': 59,\n",
              " 'i': 60,\n",
              " 'j': 61,\n",
              " 'k': 62,\n",
              " 'l': 63,\n",
              " 'm': 64,\n",
              " 'n': 65,\n",
              " 'o': 66,\n",
              " 'p': 67,\n",
              " 'q': 68,\n",
              " 'r': 69,\n",
              " 's': 70,\n",
              " 't': 71,\n",
              " 'u': 72,\n",
              " 'v': 73,\n",
              " 'w': 74,\n",
              " 'x': 75,\n",
              " 'y': 76,\n",
              " 'z': 77,\n",
              " '«': 78,\n",
              " '°': 79,\n",
              " 'º': 80,\n",
              " '»': 81,\n",
              " 'À': 82,\n",
              " 'Â': 83,\n",
              " 'Ç': 84,\n",
              " 'È': 85,\n",
              " 'É': 86,\n",
              " 'Ê': 87,\n",
              " 'Ô': 88,\n",
              " 'à': 89,\n",
              " 'â': 90,\n",
              " 'æ': 91,\n",
              " 'ç': 92,\n",
              " 'è': 93,\n",
              " 'é': 94,\n",
              " 'ê': 95,\n",
              " 'ë': 96,\n",
              " 'î': 97,\n",
              " 'ï': 98,\n",
              " 'ñ': 99,\n",
              " 'ô': 100,\n",
              " 'ö': 101,\n",
              " 'ù': 102,\n",
              " 'û': 103,\n",
              " 'ü': 104}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Si je veux l'index numérique de la lettre G majuscule\n",
        "caractere_par_index['G']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dszN-ee7a8Xx",
        "outputId": "60299d0e-c6e6-47d4-af49-bee5ce098571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inverse : index par caractere"
      ],
      "metadata": {
        "id": "ptG4Y02BbJFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# On cherche a ce que la variable vocabulaire devienne un appel d'index\n",
        "index_par_caractere = np.array(vocabulaire)"
      ],
      "metadata": {
        "id": "CyRLND9HbMqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_par_caractere[31]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "U7hGtyKlbds_",
        "outputId": "8724f073-f077-4637-f10c-15b6873c686f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'G'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder tout le texte avec des entiers"
      ],
      "metadata": {
        "id": "cOutOJHzcKPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encode_texte = np.array([caractere_par_index[caractere] for caractere in texte])"
      ],
      "metadata": {
        "id": "-Zlfksf5cNnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Affichons le\n",
        "encode_texte"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRLWDLzMchFO",
        "outputId": "29dc9da2-9d54-4f7a-afae-b05f071a6e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([27, 59, 52, ..., 56, 10,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# en print\n",
        "print(encode_texte)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl_S4P9EcrLl",
        "outputId": "668553ff-eb1a-4cbb-bc25-4e47d0c92913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[27 59 52 ... 56 10  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HS\n",
        "encode_texte.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlAscrk3c4-k",
        "outputId": "a211a717-90cf-412e-f0b4-927dcbf00a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2468231,)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Exemple sur un échantillon"
      ],
      "metadata": {
        "id": "t6ZwilzQPEds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "echantillon = texte[:500]\n",
        "print(echantillon)"
      ],
      "metadata": {
        "id": "gp0pIP03PKLj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a0da7be-d7b8-4f5d-8305-731d066e887b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chapitre I\n",
            "\n",
            "Monsieur Myriel\n",
            "\n",
            "\n",
            "En 1815, M. Charles-François-Bienvenu Myriel était évêque de Digne.\n",
            "C'était un vieillard d'environ soixante-quinze ans; il occupait le siège\n",
            "de Digne depuis 1806.\n",
            "\n",
            "Quoique ce détail ne touche en aucune manière au fond même de ce que\n",
            "nous avons à raconter, il n'est peut-être pas inutile, ne fût-ce que\n",
            "pour être exact en tout, d'indiquer ici les bruits et les propos qui\n",
            "avaient couru sur son compte au moment où il était arrivé dans le\n",
            "diocèse. Vrai ou faux, ce qu'on d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Version encodée\n",
        "print(encode_texte[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD4hC-Z2PVe0",
        "outputId": "5db161c9-9188-40c9-83cf-4119fc46c040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 27  59  52  67  60  71  69  56   1  33   0   0  37  66  65  70  60  56\n",
            "  72  69   1  37  76  69  60  56  63   0   0   0  29  65   1  13  20  13\n",
            "  17   8   1  37  10   1  27  59  52  69  63  56  70   9  30  69  52  65\n",
            "  92  66  60  70   9  26  60  56  65  73  56  65  72   1  37  76  69  60\n",
            "  56  63   1  94  71  52  60  71   1  94  73  95  68  72  56   1  55  56\n",
            "   1  28  60  58  65  56  10   0  27   4  94  71  52  60  71   1  72  65\n",
            "   1  73  60  56  60  63  63  52  69  55   1  55   4  56  65  73  60  69\n",
            "  66  65   1  70  66  60  75  52  65  71  56   9  68  72  60  65  77  56\n",
            "   1  52  65  70  23   1  60  63   1  66  54  54  72  67  52  60  71   1\n",
            "  63  56   1  70  60  93  58  56   0  55  56   1  28  60  58  65  56   1\n",
            "  55  56  67  72  60  70   1  13  20  12  18  10   0   0  41  72  66  60\n",
            "  68  72  56   1  54  56   1  55  94  71  52  60  63   1  65  56   1  71\n",
            "  66  72  54  59  56   1  56  65   1  52  72  54  72  65  56   1  64  52\n",
            "  65  60  93  69  56   1  52  72   1  57  66  65  55   1  64  95  64  56\n",
            "   1  55  56   1  54  56   1  68  72  56   0  65  66  72  70   1  52  73\n",
            "  66  65  70   1  89   1  69  52  54  66  65  71  56  69   8   1  60  63\n",
            "   1  65   4  56  70  71   1  67  56  72  71   9  95  71  69  56   1  67\n",
            "  52  70   1  60  65  72  71  60  63  56   8   1  65  56   1  57 103  71\n",
            "   9  54  56   1  68  72  56   0  67  66  72  69   1  95  71  69  56   1\n",
            "  56  75  52  54  71   1  56  65   1  71  66  72  71   8   1  55   4  60\n",
            "  65  55  60  68  72  56  69   1  60  54  60   1  63  56  70   1  53  69\n",
            "  72  60  71  70   1  56  71   1  63  56  70   1  67  69  66  67  66  70\n",
            "   1  68  72  60   0  52  73  52  60  56  65  71   1  54  66  72  69  72\n",
            "   1  70  72  69   1  70  66  65   1  54  66  64  67  71  56   1  52  72\n",
            "   1  64  66  64  56  65  71   1  66 102   1  60  63   1  94  71  52  60\n",
            "  71   1  52  69  69  60  73  94   1  55  52  65  70   1  63  56   0  55\n",
            "  60  66  54  93  70  56  10   1  46  69  52  60   1  66  72   1  57  52\n",
            "  72  75   8   1  54  56   1  68  72   4  66  65   1  55]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Création des batches"
      ],
      "metadata": {
        "id": "WdFK7b5ZPitZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour rappel : notre modèle se base sur le caractère"
      ],
      "metadata": {
        "id": "1fbY_tbbPw_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(texte[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBiRe8TPPlwP",
        "outputId": "d33a9586-710a-490d-b568-b540a4a8632c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chapitre I\n",
            "\n",
            "Monsieur Myriel\n",
            "\n",
            "\n",
            "En 1815, M. Charles-François-Bienvenu Myriel était évêque de Digne.\n",
            "C'était un vieillard d'environ soixante-quinze ans; il occupait le siège\n",
            "de Digne depuis 1806.\n",
            "\n",
            "Quoique ce détail ne touche en aucune manière au fond même de ce que\n",
            "nous avons à raconter, il n'est peut-être pas inutile, ne fût-ce que\n",
            "pour être exact en tout, d'indiquer ici les bruits et les propos qui\n",
            "avaient couru sur son compte au moment où il était arrivé dans le\n",
            "diocèse. Vrai ou faux, ce qu'on d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prenons une ligne de notre chapitre 1\n",
        "ligne = \"En 1815, M. Charles-François-Bienvenu Myriel était évêque de Digne.\"\n",
        "# Regardons la longueur\n",
        "len(ligne)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6sZVBNyQjXA",
        "outputId": "349ae9f1-5b2b-41f1-c301-949f5208d206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nbre de caractere pour une sequence de la taille de mon premier paragraphe\n",
        "lignes = '''\n",
        "En 1815, M. Charles-François-Bienvenu Myriel était évêque de Digne.\n",
        "C'était un vieillard d'environ soixante-quinze ans; il occupait le siège\n",
        "de Digne depuis 1806.\n",
        "  '''\n",
        "\n",
        "len(lignes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK0NG6E6RLrU",
        "outputId": "8fbd9ae0-5deb-4e4c-fd9c-65dbe3c19f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "166"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Autre bout de texte\n",
        "lignes_bis = '''\n",
        "Quoique ce détail ne touche en aucune manière au fond même de ce que\n",
        "nous avons à raconter, il n'est peut-être pas inutile, ne fût-ce que\n",
        "pour être exact en tout, d'indiquer ici les bruits et les propos qui\n",
        "avaient couru sur son compte au moment où il était arrivé dans le\n",
        "diocèse.\n",
        "  '''\n",
        "\n",
        "len(lignes_bis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T-HRfY-TH3T",
        "outputId": "f7390af6-e53e-4fbb-ab53-f14685fb591c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "285"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mon choix perso :\n",
        "- un cas à 150 caracteres\n",
        "- 2e cas à 250"
      ],
      "metadata": {
        "id": "8Y2PbE6cSmQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_len = 250"
      ],
      "metadata": {
        "id": "3jplJctxSn3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculons le nbre total de séquences dans notre texte"
      ],
      "metadata": {
        "id": "Pd_DBYl2VGP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# On prendre la longueur totale du texte\n",
        "# // -> permet une division qui arrondit le résultat en nombre entier\n",
        "# +1 falcutatif, je cherche a enlever l'index 0 pour d'éventuelles erreurs futures\n",
        "nb_sequences_totales = len(texte) // (sequence_len+1)\n",
        "\n",
        "# On affiche le résultat\n",
        "print(nb_sequences_totales)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXvqTHG0VPTU",
        "outputId": "8f543234-e18f-4271-fc3f-171003a29db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Création des séquences"
      ],
      "metadata": {
        "id": "Q9twoNYIXkVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On va créer les séquences d'entrainbement grace à l'objet spécial Dataset de tensorflow"
      ],
      "metadata": {
        "id": "x7txHV5RXnpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# On appelle tf.data.Dataset\n",
        "#On le construit avec from_tensor_slices()\n",
        "# On lui passe la variable du texte encodé\n",
        "dataset_caractere = tf.data.Dataset.from_tensor_slices(encode_texte)"
      ],
      "metadata": {
        "id": "wfxYLMSwYiaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifions le type de la variable dataset_caractere\n",
        "type(dataset_caractere)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot_972b1ZBmg",
        "outputId": "ed94dfd8-e29e-41ef-e062-09e74a479b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On va utiliser la méthode \"batch\""
      ],
      "metadata": {
        "id": "TEzQ1XfvZZtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for item in dataset_caractere.take(500):\n",
        "  # On affiche ces éléments en numpy\n",
        "  print(item.numpy())"
      ],
      "metadata": {
        "id": "tOLVZFxvZc6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f566d4d-2475-45a3-ebeb-f44a109b655d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n",
            "59\n",
            "52\n",
            "67\n",
            "60\n",
            "71\n",
            "69\n",
            "56\n",
            "1\n",
            "33\n",
            "0\n",
            "0\n",
            "37\n",
            "66\n",
            "65\n",
            "70\n",
            "60\n",
            "56\n",
            "72\n",
            "69\n",
            "1\n",
            "37\n",
            "76\n",
            "69\n",
            "60\n",
            "56\n",
            "63\n",
            "0\n",
            "0\n",
            "0\n",
            "29\n",
            "65\n",
            "1\n",
            "13\n",
            "20\n",
            "13\n",
            "17\n",
            "8\n",
            "1\n",
            "37\n",
            "10\n",
            "1\n",
            "27\n",
            "59\n",
            "52\n",
            "69\n",
            "63\n",
            "56\n",
            "70\n",
            "9\n",
            "30\n",
            "69\n",
            "52\n",
            "65\n",
            "92\n",
            "66\n",
            "60\n",
            "70\n",
            "9\n",
            "26\n",
            "60\n",
            "56\n",
            "65\n",
            "73\n",
            "56\n",
            "65\n",
            "72\n",
            "1\n",
            "37\n",
            "76\n",
            "69\n",
            "60\n",
            "56\n",
            "63\n",
            "1\n",
            "94\n",
            "71\n",
            "52\n",
            "60\n",
            "71\n",
            "1\n",
            "94\n",
            "73\n",
            "95\n",
            "68\n",
            "72\n",
            "56\n",
            "1\n",
            "55\n",
            "56\n",
            "1\n",
            "28\n",
            "60\n",
            "58\n",
            "65\n",
            "56\n",
            "10\n",
            "0\n",
            "27\n",
            "4\n",
            "94\n",
            "71\n",
            "52\n",
            "60\n",
            "71\n",
            "1\n",
            "72\n",
            "65\n",
            "1\n",
            "73\n",
            "60\n",
            "56\n",
            "60\n",
            "63\n",
            "63\n",
            "52\n",
            "69\n",
            "55\n",
            "1\n",
            "55\n",
            "4\n",
            "56\n",
            "65\n",
            "73\n",
            "60\n",
            "69\n",
            "66\n",
            "65\n",
            "1\n",
            "70\n",
            "66\n",
            "60\n",
            "75\n",
            "52\n",
            "65\n",
            "71\n",
            "56\n",
            "9\n",
            "68\n",
            "72\n",
            "60\n",
            "65\n",
            "77\n",
            "56\n",
            "1\n",
            "52\n",
            "65\n",
            "70\n",
            "23\n",
            "1\n",
            "60\n",
            "63\n",
            "1\n",
            "66\n",
            "54\n",
            "54\n",
            "72\n",
            "67\n",
            "52\n",
            "60\n",
            "71\n",
            "1\n",
            "63\n",
            "56\n",
            "1\n",
            "70\n",
            "60\n",
            "93\n",
            "58\n",
            "56\n",
            "0\n",
            "55\n",
            "56\n",
            "1\n",
            "28\n",
            "60\n",
            "58\n",
            "65\n",
            "56\n",
            "1\n",
            "55\n",
            "56\n",
            "67\n",
            "72\n",
            "60\n",
            "70\n",
            "1\n",
            "13\n",
            "20\n",
            "12\n",
            "18\n",
            "10\n",
            "0\n",
            "0\n",
            "41\n",
            "72\n",
            "66\n",
            "60\n",
            "68\n",
            "72\n",
            "56\n",
            "1\n",
            "54\n",
            "56\n",
            "1\n",
            "55\n",
            "94\n",
            "71\n",
            "52\n",
            "60\n",
            "63\n",
            "1\n",
            "65\n",
            "56\n",
            "1\n",
            "71\n",
            "66\n",
            "72\n",
            "54\n",
            "59\n",
            "56\n",
            "1\n",
            "56\n",
            "65\n",
            "1\n",
            "52\n",
            "72\n",
            "54\n",
            "72\n",
            "65\n",
            "56\n",
            "1\n",
            "64\n",
            "52\n",
            "65\n",
            "60\n",
            "93\n",
            "69\n",
            "56\n",
            "1\n",
            "52\n",
            "72\n",
            "1\n",
            "57\n",
            "66\n",
            "65\n",
            "55\n",
            "1\n",
            "64\n",
            "95\n",
            "64\n",
            "56\n",
            "1\n",
            "55\n",
            "56\n",
            "1\n",
            "54\n",
            "56\n",
            "1\n",
            "68\n",
            "72\n",
            "56\n",
            "0\n",
            "65\n",
            "66\n",
            "72\n",
            "70\n",
            "1\n",
            "52\n",
            "73\n",
            "66\n",
            "65\n",
            "70\n",
            "1\n",
            "89\n",
            "1\n",
            "69\n",
            "52\n",
            "54\n",
            "66\n",
            "65\n",
            "71\n",
            "56\n",
            "69\n",
            "8\n",
            "1\n",
            "60\n",
            "63\n",
            "1\n",
            "65\n",
            "4\n",
            "56\n",
            "70\n",
            "71\n",
            "1\n",
            "67\n",
            "56\n",
            "72\n",
            "71\n",
            "9\n",
            "95\n",
            "71\n",
            "69\n",
            "56\n",
            "1\n",
            "67\n",
            "52\n",
            "70\n",
            "1\n",
            "60\n",
            "65\n",
            "72\n",
            "71\n",
            "60\n",
            "63\n",
            "56\n",
            "8\n",
            "1\n",
            "65\n",
            "56\n",
            "1\n",
            "57\n",
            "103\n",
            "71\n",
            "9\n",
            "54\n",
            "56\n",
            "1\n",
            "68\n",
            "72\n",
            "56\n",
            "0\n",
            "67\n",
            "66\n",
            "72\n",
            "69\n",
            "1\n",
            "95\n",
            "71\n",
            "69\n",
            "56\n",
            "1\n",
            "56\n",
            "75\n",
            "52\n",
            "54\n",
            "71\n",
            "1\n",
            "56\n",
            "65\n",
            "1\n",
            "71\n",
            "66\n",
            "72\n",
            "71\n",
            "8\n",
            "1\n",
            "55\n",
            "4\n",
            "60\n",
            "65\n",
            "55\n",
            "60\n",
            "68\n",
            "72\n",
            "56\n",
            "69\n",
            "1\n",
            "60\n",
            "54\n",
            "60\n",
            "1\n",
            "63\n",
            "56\n",
            "70\n",
            "1\n",
            "53\n",
            "69\n",
            "72\n",
            "60\n",
            "71\n",
            "70\n",
            "1\n",
            "56\n",
            "71\n",
            "1\n",
            "63\n",
            "56\n",
            "70\n",
            "1\n",
            "67\n",
            "69\n",
            "66\n",
            "67\n",
            "66\n",
            "70\n",
            "1\n",
            "68\n",
            "72\n",
            "60\n",
            "0\n",
            "52\n",
            "73\n",
            "52\n",
            "60\n",
            "56\n",
            "65\n",
            "71\n",
            "1\n",
            "54\n",
            "66\n",
            "72\n",
            "69\n",
            "72\n",
            "1\n",
            "70\n",
            "72\n",
            "69\n",
            "1\n",
            "70\n",
            "66\n",
            "65\n",
            "1\n",
            "54\n",
            "66\n",
            "64\n",
            "67\n",
            "71\n",
            "56\n",
            "1\n",
            "52\n",
            "72\n",
            "1\n",
            "64\n",
            "66\n",
            "64\n",
            "56\n",
            "65\n",
            "71\n",
            "1\n",
            "66\n",
            "102\n",
            "1\n",
            "60\n",
            "63\n",
            "1\n",
            "94\n",
            "71\n",
            "52\n",
            "60\n",
            "71\n",
            "1\n",
            "52\n",
            "69\n",
            "69\n",
            "60\n",
            "73\n",
            "94\n",
            "1\n",
            "55\n",
            "52\n",
            "65\n",
            "70\n",
            "1\n",
            "63\n",
            "56\n",
            "0\n",
            "55\n",
            "60\n",
            "66\n",
            "54\n",
            "93\n",
            "70\n",
            "56\n",
            "10\n",
            "1\n",
            "46\n",
            "69\n",
            "52\n",
            "60\n",
            "1\n",
            "66\n",
            "72\n",
            "1\n",
            "57\n",
            "52\n",
            "72\n",
            "75\n",
            "8\n",
            "1\n",
            "54\n",
            "56\n",
            "1\n",
            "68\n",
            "72\n",
            "4\n",
            "66\n",
            "65\n",
            "1\n",
            "55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inversons\n",
        "for item in dataset_caractere.take(500):\n",
        "  print(index_par_caractere[item.numpy()])"
      ],
      "metadata": {
        "id": "K2OIJTK4aQNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81676632-ec9a-4a8f-cc0c-9990878112dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C\n",
            "h\n",
            "a\n",
            "p\n",
            "i\n",
            "t\n",
            "r\n",
            "e\n",
            " \n",
            "I\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "M\n",
            "o\n",
            "n\n",
            "s\n",
            "i\n",
            "e\n",
            "u\n",
            "r\n",
            " \n",
            "M\n",
            "y\n",
            "r\n",
            "i\n",
            "e\n",
            "l\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "E\n",
            "n\n",
            " \n",
            "1\n",
            "8\n",
            "1\n",
            "5\n",
            ",\n",
            " \n",
            "M\n",
            ".\n",
            " \n",
            "C\n",
            "h\n",
            "a\n",
            "r\n",
            "l\n",
            "e\n",
            "s\n",
            "-\n",
            "F\n",
            "r\n",
            "a\n",
            "n\n",
            "ç\n",
            "o\n",
            "i\n",
            "s\n",
            "-\n",
            "B\n",
            "i\n",
            "e\n",
            "n\n",
            "v\n",
            "e\n",
            "n\n",
            "u\n",
            " \n",
            "M\n",
            "y\n",
            "r\n",
            "i\n",
            "e\n",
            "l\n",
            " \n",
            "é\n",
            "t\n",
            "a\n",
            "i\n",
            "t\n",
            " \n",
            "é\n",
            "v\n",
            "ê\n",
            "q\n",
            "u\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            " \n",
            "D\n",
            "i\n",
            "g\n",
            "n\n",
            "e\n",
            ".\n",
            "\n",
            "\n",
            "C\n",
            "'\n",
            "é\n",
            "t\n",
            "a\n",
            "i\n",
            "t\n",
            " \n",
            "u\n",
            "n\n",
            " \n",
            "v\n",
            "i\n",
            "e\n",
            "i\n",
            "l\n",
            "l\n",
            "a\n",
            "r\n",
            "d\n",
            " \n",
            "d\n",
            "'\n",
            "e\n",
            "n\n",
            "v\n",
            "i\n",
            "r\n",
            "o\n",
            "n\n",
            " \n",
            "s\n",
            "o\n",
            "i\n",
            "x\n",
            "a\n",
            "n\n",
            "t\n",
            "e\n",
            "-\n",
            "q\n",
            "u\n",
            "i\n",
            "n\n",
            "z\n",
            "e\n",
            " \n",
            "a\n",
            "n\n",
            "s\n",
            ";\n",
            " \n",
            "i\n",
            "l\n",
            " \n",
            "o\n",
            "c\n",
            "c\n",
            "u\n",
            "p\n",
            "a\n",
            "i\n",
            "t\n",
            " \n",
            "l\n",
            "e\n",
            " \n",
            "s\n",
            "i\n",
            "è\n",
            "g\n",
            "e\n",
            "\n",
            "\n",
            "d\n",
            "e\n",
            " \n",
            "D\n",
            "i\n",
            "g\n",
            "n\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "p\n",
            "u\n",
            "i\n",
            "s\n",
            " \n",
            "1\n",
            "8\n",
            "0\n",
            "6\n",
            ".\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Q\n",
            "u\n",
            "o\n",
            "i\n",
            "q\n",
            "u\n",
            "e\n",
            " \n",
            "c\n",
            "e\n",
            " \n",
            "d\n",
            "é\n",
            "t\n",
            "a\n",
            "i\n",
            "l\n",
            " \n",
            "n\n",
            "e\n",
            " \n",
            "t\n",
            "o\n",
            "u\n",
            "c\n",
            "h\n",
            "e\n",
            " \n",
            "e\n",
            "n\n",
            " \n",
            "a\n",
            "u\n",
            "c\n",
            "u\n",
            "n\n",
            "e\n",
            " \n",
            "m\n",
            "a\n",
            "n\n",
            "i\n",
            "è\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "u\n",
            " \n",
            "f\n",
            "o\n",
            "n\n",
            "d\n",
            " \n",
            "m\n",
            "ê\n",
            "m\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            " \n",
            "c\n",
            "e\n",
            " \n",
            "q\n",
            "u\n",
            "e\n",
            "\n",
            "\n",
            "n\n",
            "o\n",
            "u\n",
            "s\n",
            " \n",
            "a\n",
            "v\n",
            "o\n",
            "n\n",
            "s\n",
            " \n",
            "à\n",
            " \n",
            "r\n",
            "a\n",
            "c\n",
            "o\n",
            "n\n",
            "t\n",
            "e\n",
            "r\n",
            ",\n",
            " \n",
            "i\n",
            "l\n",
            " \n",
            "n\n",
            "'\n",
            "e\n",
            "s\n",
            "t\n",
            " \n",
            "p\n",
            "e\n",
            "u\n",
            "t\n",
            "-\n",
            "ê\n",
            "t\n",
            "r\n",
            "e\n",
            " \n",
            "p\n",
            "a\n",
            "s\n",
            " \n",
            "i\n",
            "n\n",
            "u\n",
            "t\n",
            "i\n",
            "l\n",
            "e\n",
            ",\n",
            " \n",
            "n\n",
            "e\n",
            " \n",
            "f\n",
            "û\n",
            "t\n",
            "-\n",
            "c\n",
            "e\n",
            " \n",
            "q\n",
            "u\n",
            "e\n",
            "\n",
            "\n",
            "p\n",
            "o\n",
            "u\n",
            "r\n",
            " \n",
            "ê\n",
            "t\n",
            "r\n",
            "e\n",
            " \n",
            "e\n",
            "x\n",
            "a\n",
            "c\n",
            "t\n",
            " \n",
            "e\n",
            "n\n",
            " \n",
            "t\n",
            "o\n",
            "u\n",
            "t\n",
            ",\n",
            " \n",
            "d\n",
            "'\n",
            "i\n",
            "n\n",
            "d\n",
            "i\n",
            "q\n",
            "u\n",
            "e\n",
            "r\n",
            " \n",
            "i\n",
            "c\n",
            "i\n",
            " \n",
            "l\n",
            "e\n",
            "s\n",
            " \n",
            "b\n",
            "r\n",
            "u\n",
            "i\n",
            "t\n",
            "s\n",
            " \n",
            "e\n",
            "t\n",
            " \n",
            "l\n",
            "e\n",
            "s\n",
            " \n",
            "p\n",
            "r\n",
            "o\n",
            "p\n",
            "o\n",
            "s\n",
            " \n",
            "q\n",
            "u\n",
            "i\n",
            "\n",
            "\n",
            "a\n",
            "v\n",
            "a\n",
            "i\n",
            "e\n",
            "n\n",
            "t\n",
            " \n",
            "c\n",
            "o\n",
            "u\n",
            "r\n",
            "u\n",
            " \n",
            "s\n",
            "u\n",
            "r\n",
            " \n",
            "s\n",
            "o\n",
            "n\n",
            " \n",
            "c\n",
            "o\n",
            "m\n",
            "p\n",
            "t\n",
            "e\n",
            " \n",
            "a\n",
            "u\n",
            " \n",
            "m\n",
            "o\n",
            "m\n",
            "e\n",
            "n\n",
            "t\n",
            " \n",
            "o\n",
            "ù\n",
            " \n",
            "i\n",
            "l\n",
            " \n",
            "é\n",
            "t\n",
            "a\n",
            "i\n",
            "t\n",
            " \n",
            "a\n",
            "r\n",
            "r\n",
            "i\n",
            "v\n",
            "é\n",
            " \n",
            "d\n",
            "a\n",
            "n\n",
            "s\n",
            " \n",
            "l\n",
            "e\n",
            "\n",
            "\n",
            "d\n",
            "i\n",
            "o\n",
            "c\n",
            "è\n",
            "s\n",
            "e\n",
            ".\n",
            " \n",
            "V\n",
            "r\n",
            "a\n",
            "i\n",
            " \n",
            "o\n",
            "u\n",
            " \n",
            "f\n",
            "a\n",
            "u\n",
            "x\n",
            ",\n",
            " \n",
            "c\n",
            "e\n",
            " \n",
            "q\n",
            "u\n",
            "'\n",
            "o\n",
            "n\n",
            " \n",
            "d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Création des séquences à partir du dataset créé"
      ],
      "metadata": {
        "id": "DzKlWgCfaxnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Méthode batch() pour additionner les éléments consécutis du dataset en batches\n",
        "# drop_remainder sur True pour éliminer les caractères restants, ne pouvant faire un lot de\n",
        "# 150 caractères au complet\n",
        "sequences = dataset_caractere.batch(sequence_len+1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "OWxIDc2Ga1QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Toutes nos séquences :\n",
        "- on va saisir la séquence de texte d'entrée\n",
        "- Ensuite assigner la séquence de texte cible en tant que séquence de texte d'entrée décalée d'un pas en avant\n",
        "\n"
      ],
      "metadata": {
        "id": "XtSvcGoLbt_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction pour créer des sequences ciblées\n",
        "def create_sequences_ciblees(sequence):\n",
        "  #Le texte d'entrée sera = a la sequence depuis le début (:) jusqu'au dernier caractère non inclus (-1)\n",
        "  input_texte = sequence[:-1] #Bonjou\n",
        "  # On assigne la séquence de texte cible, en la rendant = à la séquence décalée d'un pas en avant\n",
        "  cible_texte = sequence[1:]  #onjour\n",
        "  # On retourne le résultat\n",
        "  return input_texte, cible_texte\n"
      ],
      "metadata": {
        "id": "w0OIV9aBcHK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On mappe tout ça a toutes les séquences\n",
        "dataset = sequences.map(create_sequences_ciblees)"
      ],
      "metadata": {
        "id": "-fEhXBXUeqrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exemple pour à quoi ca ressemble"
      ],
      "metadata": {
        "id": "4w_JuEy4fHEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_texte, cible_texte in dataset.take(1):\n",
        "  # Afficher l'input_texte en tableau numpy\n",
        "  print(input_texte.numpy())\n",
        "  print(index_par_caractere[input_texte.numpy()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTfRW2lpfC_2",
        "outputId": "caeb966e-0d04-45bb-c7e7-d1f4392bd57f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[27 59 52 67 60 71 69 56  1 33  0  0 37 66 65 70 60 56 72 69  1 37 76 69\n",
            " 60 56 63  0  0  0 29 65  1 13 20 13 17  8  1 37 10  1 27 59 52 69 63 56\n",
            " 70  9 30 69 52 65 92 66 60 70  9 26 60 56 65 73 56 65 72  1 37 76 69 60\n",
            " 56 63  1 94 71 52 60 71  1 94 73 95 68 72 56  1 55 56  1 28 60 58 65 56\n",
            " 10  0 27  4 94 71 52 60 71  1 72 65  1 73 60 56 60 63 63 52 69 55  1 55\n",
            "  4 56 65 73 60 69 66 65  1 70 66 60 75 52 65 71 56  9 68 72 60 65 77 56\n",
            "  1 52 65 70 23  1 60 63  1 66 54 54 72 67 52 60 71  1 63 56  1 70 60 93\n",
            " 58 56  0 55 56  1 28 60 58 65 56  1 55 56 67 72 60 70  1 13 20 12 18 10\n",
            "  0  0 41 72 66 60 68 72 56  1 54 56  1 55 94 71 52 60 63  1 65 56  1 71\n",
            " 66 72 54 59 56  1 56 65  1 52 72 54 72 65 56  1 64 52 65 60 93 69 56  1\n",
            " 52 72  1 57 66 65 55  1 64 95]\n",
            "['C' 'h' 'a' 'p' 'i' 't' 'r' 'e' ' ' 'I' '\\n' '\\n' 'M' 'o' 'n' 's' 'i' 'e'\n",
            " 'u' 'r' ' ' 'M' 'y' 'r' 'i' 'e' 'l' '\\n' '\\n' '\\n' 'E' 'n' ' ' '1' '8'\n",
            " '1' '5' ',' ' ' 'M' '.' ' ' 'C' 'h' 'a' 'r' 'l' 'e' 's' '-' 'F' 'r' 'a'\n",
            " 'n' 'ç' 'o' 'i' 's' '-' 'B' 'i' 'e' 'n' 'v' 'e' 'n' 'u' ' ' 'M' 'y' 'r'\n",
            " 'i' 'e' 'l' ' ' 'é' 't' 'a' 'i' 't' ' ' 'é' 'v' 'ê' 'q' 'u' 'e' ' ' 'd'\n",
            " 'e' ' ' 'D' 'i' 'g' 'n' 'e' '.' '\\n' 'C' \"'\" 'é' 't' 'a' 'i' 't' ' ' 'u'\n",
            " 'n' ' ' 'v' 'i' 'e' 'i' 'l' 'l' 'a' 'r' 'd' ' ' 'd' \"'\" 'e' 'n' 'v' 'i'\n",
            " 'r' 'o' 'n' ' ' 's' 'o' 'i' 'x' 'a' 'n' 't' 'e' '-' 'q' 'u' 'i' 'n' 'z'\n",
            " 'e' ' ' 'a' 'n' 's' ';' ' ' 'i' 'l' ' ' 'o' 'c' 'c' 'u' 'p' 'a' 'i' 't'\n",
            " ' ' 'l' 'e' ' ' 's' 'i' 'è' 'g' 'e' '\\n' 'd' 'e' ' ' 'D' 'i' 'g' 'n' 'e'\n",
            " ' ' 'd' 'e' 'p' 'u' 'i' 's' ' ' '1' '8' '0' '6' '.' '\\n' '\\n' 'Q' 'u' 'o'\n",
            " 'i' 'q' 'u' 'e' ' ' 'c' 'e' ' ' 'd' 'é' 't' 'a' 'i' 'l' ' ' 'n' 'e' ' '\n",
            " 't' 'o' 'u' 'c' 'h' 'e' ' ' 'e' 'n' ' ' 'a' 'u' 'c' 'u' 'n' 'e' ' ' 'm'\n",
            " 'a' 'n' 'i' 'è' 'r' 'e' ' ' 'a' 'u' ' ' 'f' 'o' 'n' 'd' ' ' 'm' 'ê']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Maintenant on peut joindre tout ça pour que ce soit une liste\n",
        "print(''.join(index_par_caractere[input_texte.numpy()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IqeJkMZfl3F",
        "outputId": "005b722b-5927-4aa0-f206-1367363ba4fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chapitre I\n",
            "\n",
            "Monsieur Myriel\n",
            "\n",
            "\n",
            "En 1815, M. Charles-François-Bienvenu Myriel était évêque de Digne.\n",
            "C'était un vieillard d'environ soixante-quinze ans; il occupait le siège\n",
            "de Digne depuis 1806.\n",
            "\n",
            "Quoique ce détail ne touche en aucune manière au fond mê\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on peut afficher le texte cible\n",
        "print(cible_texte.numpy())\n",
        "print(''.join(index_par_caractere[cible_texte.numpy()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU3LZBfFf1G6",
        "outputId": "56d67c68-6a9e-41b8-cf18-ec6595b31d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[59 52 67 60 71 69 56  1 33  0  0 37 66 65 70 60 56 72 69  1 37 76 69 60\n",
            " 56 63  0  0  0 29 65  1 13 20 13 17  8  1 37 10  1 27 59 52 69 63 56 70\n",
            "  9 30 69 52 65 92 66 60 70  9 26 60 56 65 73 56 65 72  1 37 76 69 60 56\n",
            " 63  1 94 71 52 60 71  1 94 73 95 68 72 56  1 55 56  1 28 60 58 65 56 10\n",
            "  0 27  4 94 71 52 60 71  1 72 65  1 73 60 56 60 63 63 52 69 55  1 55  4\n",
            " 56 65 73 60 69 66 65  1 70 66 60 75 52 65 71 56  9 68 72 60 65 77 56  1\n",
            " 52 65 70 23  1 60 63  1 66 54 54 72 67 52 60 71  1 63 56  1 70 60 93 58\n",
            " 56  0 55 56  1 28 60 58 65 56  1 55 56 67 72 60 70  1 13 20 12 18 10  0\n",
            "  0 41 72 66 60 68 72 56  1 54 56  1 55 94 71 52 60 63  1 65 56  1 71 66\n",
            " 72 54 59 56  1 56 65  1 52 72 54 72 65 56  1 64 52 65 60 93 69 56  1 52\n",
            " 72  1 57 66 65 55  1 64 95 64]\n",
            "hapitre I\n",
            "\n",
            "Monsieur Myriel\n",
            "\n",
            "\n",
            "En 1815, M. Charles-François-Bienvenu Myriel était évêque de Digne.\n",
            "C'était un vieillard d'environ soixante-quinze ans; il occupait le siège\n",
            "de Digne depuis 1806.\n",
            "\n",
            "Quoique ce détail ne touche en aucune manière au fond mêm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choisir une taille de lot\n",
        "taille_batch = 128\n",
        "\n",
        "# On va le laisser mélanger toute la séquence en mémoire uniquement\n",
        "# Pour éviter un texte trop gros, qui provoquerait des erreurs\n",
        "memoire_tampon = 1000\n",
        "\n",
        "# Shuffle() pour les mélanger et batch() pour les prendre en compte\n",
        "dataset = dataset.shuffle(memoire_tampon).batch(taille_batch, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBvBVR_fQqbh",
        "outputId": "86cef5ca-3f93-4b4c-99de-8c4644710adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(128, 250), dtype=tf.int64, name=None), TensorSpec(shape=(128, 250), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Création du modèle"
      ],
      "metadata": {
        "id": "20KsnrIXSXV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# La longueur de notre vocabulaire\n",
        "vocabulaire_size = len(vocabulaire)\n",
        "print(vocabulaire_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDyAtZD_SbGk",
        "outputId": "29181863-3ff1-40c6-8836-c51c5a1fd336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pour notre couche de embedding, on va définir la dimension embedding\n",
        "#Une trop grande valeur entrainera des features inutiles\n",
        "embed_dimension = 85"
      ],
      "metadata": {
        "id": "aa5LcJwBTlsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Une couche RNN avec le GRU\n",
        "# Choisir le nbre de neurones (il doit etre conséquent)\n",
        "rnn_neurones = 1026"
      ],
      "metadata": {
        "id": "zZwdzHnAT-zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fonction de perte (appelé loss)"
      ],
      "metadata": {
        "id": "srpN6Jq1Ufo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ],
      "metadata": {
        "id": "o7bYDoA8Ui07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(sparse_categorical_crossentropy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX2W8Ek8U490",
        "outputId": "15156e82-32c1-4006-a85f-33c605ecca62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function sparse_categorical_crossentropy in module keras.losses:\n",
            "\n",
            "sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1, ignore_class=None)\n",
            "    Computes the sparse categorical crossentropy loss.\n",
            "    \n",
            "    Standalone usage:\n",
            "    \n",
            "    >>> y_true = [1, 2]\n",
            "    >>> y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
            "    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
            "    >>> assert loss.shape == (2,)\n",
            "    >>> loss.numpy()\n",
            "    array([0.0513, 2.303], dtype=float32)\n",
            "    \n",
            "    >>> y_true = [[[ 0,  2],\n",
            "    ...            [-1, -1]],\n",
            "    ...           [[ 0,  2],\n",
            "    ...            [-1, -1]]]\n",
            "    >>> y_pred = [[[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]],\n",
            "    ...             [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]],\n",
            "    ...           [[[1.0, 0.0, 0.0], [0.0, 0.5, 0.5]],\n",
            "    ...            [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]]]\n",
            "    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
            "    ...   y_true, y_pred, ignore_class=-1)\n",
            "    >>> loss.numpy()\n",
            "    array([[[2.3841855e-07, 2.3841855e-07],\n",
            "            [0.0000000e+00, 0.0000000e+00]],\n",
            "           [[2.3841855e-07, 6.9314730e-01],\n",
            "            [0.0000000e+00, 0.0000000e+00]]], dtype=float32)\n",
            "    \n",
            "    Args:\n",
            "      y_true: Ground truth values.\n",
            "      y_pred: The predicted values.\n",
            "      from_logits: Whether `y_pred` is expected to be a logits tensor. By\n",
            "        default, we assume that `y_pred` encodes a probability distribution.\n",
            "      axis: Defaults to -1. The dimension along which the entropy is\n",
            "        computed.\n",
            "      ignore_class: Optional integer. The ID of a class to be ignored during\n",
            "        loss computation. This is useful, for example, in segmentation\n",
            "        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n",
            "        maps. By default (`ignore_class=None`), all classes are considered.\n",
            "    \n",
            "    Returns:\n",
            "      Sparse categorical crossentropy loss value.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Créer la fonction de perte\n",
        "def perte_categorielle(y_true, y_pred):\n",
        "  return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
      ],
      "metadata": {
        "id": "rp-Amum_VTsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Création du modele\n",
        "\n",
        "# Imports\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "\n",
        "# Fonction\n",
        "def create_modele(vocabulaire_size, embed_dimension, rnn_neurones, taille_batch):\n",
        "  modele = Sequential()\n",
        "\n",
        "  modele.add(Embedding(vocabulaire_size, embed_dimension, batch_input_shape=[taille_batch, None]))\n",
        "  modele.add(GRU(rnn_neurones, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'))\n",
        "  modele.add(Dense(vocabulaire_size))\n",
        "\n",
        "  modele.compile(optimizer='adam',loss=perte_categorielle)\n",
        "\n",
        "  return modele"
      ],
      "metadata": {
        "id": "2iMdf7PFVvrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modele = create_modele(vocabulaire_size=vocabulaire_size,\n",
        "                       embed_dimension= embed_dimension,\n",
        "                       rnn_neurones=rnn_neurones,\n",
        "                       taille_batch=taille_batch)"
      ],
      "metadata": {
        "id": "8CihKck_aWYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modele.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3UIbKRGa2T1",
        "outputId": "7c947db1-408e-42d4-ac97-c1ea20e14c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (128, None, 85)           8925      \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (128, None, 1026)         3425814   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (128, None, 105)          107835    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,542,574\n",
            "Trainable params: 3,542,574\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrainement du modele"
      ],
      "metadata": {
        "id": "msBJ-Fdlb708"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verification du code , si tout est ok"
      ],
      "metadata": {
        "id": "zgDi96VOcq3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Executer le modele sur un batch d'entrée\n",
        "for batch_texte_exemple, batch_cible_exemple in dataset.take(1):\n",
        "  exemple_batch_prediction = modele(batch_texte_exemple)\n",
        "\n",
        "exemple_batch_prediction.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyaDCWeFb7id",
        "outputId": "0c998094-a45e-41fd-c988-97a8f16a07f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([128, 250, 105])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Premier element\n",
        "exemple_batch_prediction[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEp6Q8DGd40L",
        "outputId": "088c0ec2-c212-46a8-a3fc-780f09071c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(250, 105), dtype=float32, numpy=\n",
              "array([[ 5.1518474e-03,  1.9271219e-03,  2.4171779e-05, ...,\n",
              "         1.1323937e-03,  1.0207861e-03,  1.0992355e-02],\n",
              "       [ 1.3680205e-03,  3.1512084e-03,  8.3188657e-03, ...,\n",
              "        -1.1648999e-03, -1.3975953e-03,  9.4194449e-03],\n",
              "       [-3.7204302e-03,  5.3808433e-03, -2.5735563e-03, ...,\n",
              "        -2.8853910e-04,  1.0330009e-04, -2.5053713e-03],\n",
              "       ...,\n",
              "       [-6.7539765e-03, -5.1646526e-03, -9.7643249e-03, ...,\n",
              "        -5.5138674e-03, -7.6250331e-03,  2.2871559e-04],\n",
              "       [-5.6019891e-03, -9.2105824e-04,  4.6105525e-03, ...,\n",
              "        -5.2402294e-03, -7.5906450e-03,  4.9012406e-03],\n",
              "       [ 3.5162112e-03, -5.8422890e-04,  9.5229922e-04, ...,\n",
              "        -2.3520177e-03,  6.0776970e-04,  3.2177595e-03]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On va ajouter un nbre d'echantillon a saisir\n",
        "echantillon_indices = tf.random.categorical(exemple_batch_prediction[0], num_samples=1)\n",
        "\n",
        "print(echantillon_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7imXiCmNeTzy",
        "outputId": "59c0b227-c20e-4df0-b795-4a74ccb38c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 75]\n",
            " [  6]\n",
            " [ 51]\n",
            " [ 83]\n",
            " [ 62]\n",
            " [ 98]\n",
            " [ 79]\n",
            " [100]\n",
            " [ 35]\n",
            " [ 33]\n",
            " [ 10]\n",
            " [ 20]\n",
            " [ 21]\n",
            " [  3]\n",
            " [ 73]\n",
            " [ 74]\n",
            " [102]\n",
            " [103]\n",
            " [103]\n",
            " [ 73]\n",
            " [ 69]\n",
            " [ 18]\n",
            " [ 79]\n",
            " [100]\n",
            " [100]\n",
            " [ 70]\n",
            " [ 74]\n",
            " [ 20]\n",
            " [ 90]\n",
            " [ 48]\n",
            " [ 55]\n",
            " [ 39]\n",
            " [ 29]\n",
            " [ 94]\n",
            " [  1]\n",
            " [ 63]\n",
            " [102]\n",
            " [ 74]\n",
            " [ 51]\n",
            " [  0]\n",
            " [ 68]\n",
            " [ 39]\n",
            " [ 36]\n",
            " [ 96]\n",
            " [ 47]\n",
            " [ 62]\n",
            " [ 78]\n",
            " [ 49]\n",
            " [ 31]\n",
            " [ 12]\n",
            " [ 34]\n",
            " [100]\n",
            " [ 66]\n",
            " [ 38]\n",
            " [ 31]\n",
            " [  0]\n",
            " [ 11]\n",
            " [ 16]\n",
            " [ 19]\n",
            " [ 31]\n",
            " [ 40]\n",
            " [ 50]\n",
            " [ 17]\n",
            " [ 33]\n",
            " [ 16]\n",
            " [ 13]\n",
            " [ 38]\n",
            " [ 89]\n",
            " [  2]\n",
            " [ 71]\n",
            " [ 51]\n",
            " [ 36]\n",
            " [ 19]\n",
            " [ 17]\n",
            " [ 74]\n",
            " [ 51]\n",
            " [ 83]\n",
            " [ 34]\n",
            " [ 26]\n",
            " [ 23]\n",
            " [  0]\n",
            " [ 10]\n",
            " [ 51]\n",
            " [ 62]\n",
            " [ 86]\n",
            " [ 96]\n",
            " [ 12]\n",
            " [ 36]\n",
            " [ 62]\n",
            " [ 42]\n",
            " [ 35]\n",
            " [ 70]\n",
            " [ 66]\n",
            " [ 93]\n",
            " [ 22]\n",
            " [ 21]\n",
            " [ 38]\n",
            " [ 66]\n",
            " [ 30]\n",
            " [ 20]\n",
            " [ 50]\n",
            " [ 87]\n",
            " [ 75]\n",
            " [ 21]\n",
            " [ 51]\n",
            " [ 77]\n",
            " [ 53]\n",
            " [ 87]\n",
            " [ 24]\n",
            " [ 94]\n",
            " [ 51]\n",
            " [ 12]\n",
            " [ 31]\n",
            " [ 76]\n",
            " [ 87]\n",
            " [ 94]\n",
            " [ 88]\n",
            " [ 40]\n",
            " [100]\n",
            " [ 53]\n",
            " [ 70]\n",
            " [ 60]\n",
            " [ 55]\n",
            " [ 98]\n",
            " [ 42]\n",
            " [ 33]\n",
            " [ 33]\n",
            " [ 76]\n",
            " [ 85]\n",
            " [ 89]\n",
            " [ 47]\n",
            " [ 73]\n",
            " [  4]\n",
            " [ 25]\n",
            " [ 85]\n",
            " [  2]\n",
            " [ 99]\n",
            " [ 73]\n",
            " [ 44]\n",
            " [ 31]\n",
            " [ 46]\n",
            " [ 66]\n",
            " [ 45]\n",
            " [ 61]\n",
            " [ 16]\n",
            " [ 16]\n",
            " [  4]\n",
            " [ 81]\n",
            " [ 95]\n",
            " [ 47]\n",
            " [  7]\n",
            " [ 80]\n",
            " [ 26]\n",
            " [ 59]\n",
            " [ 40]\n",
            " [ 53]\n",
            " [ 40]\n",
            " [ 99]\n",
            " [ 29]\n",
            " [ 82]\n",
            " [  0]\n",
            " [ 23]\n",
            " [ 47]\n",
            " [ 71]\n",
            " [  0]\n",
            " [103]\n",
            " [ 57]\n",
            " [ 30]\n",
            " [ 36]\n",
            " [ 54]\n",
            " [ 32]\n",
            " [ 23]\n",
            " [ 80]\n",
            " [ 12]\n",
            " [ 30]\n",
            " [  4]\n",
            " [ 63]\n",
            " [ 38]\n",
            " [ 70]\n",
            " [ 15]\n",
            " [ 88]\n",
            " [100]\n",
            " [ 40]\n",
            " [ 38]\n",
            " [ 29]\n",
            " [ 64]\n",
            " [ 27]\n",
            " [ 92]\n",
            " [ 14]\n",
            " [ 83]\n",
            " [ 34]\n",
            " [ 61]\n",
            " [ 87]\n",
            " [ 30]\n",
            " [ 98]\n",
            " [ 41]\n",
            " [ 40]\n",
            " [  1]\n",
            " [ 98]\n",
            " [  6]\n",
            " [ 65]\n",
            " [ 33]\n",
            " [ 86]\n",
            " [ 84]\n",
            " [ 42]\n",
            " [ 75]\n",
            " [ 60]\n",
            " [  1]\n",
            " [ 69]\n",
            " [ 89]\n",
            " [ 62]\n",
            " [ 65]\n",
            " [ 91]\n",
            " [ 69]\n",
            " [ 54]\n",
            " [ 49]\n",
            " [  1]\n",
            " [ 65]\n",
            " [ 13]\n",
            " [ 95]\n",
            " [ 12]\n",
            " [ 50]\n",
            " [ 37]\n",
            " [ 45]\n",
            " [ 97]\n",
            " [ 10]\n",
            " [ 64]\n",
            " [ 64]\n",
            " [ 33]\n",
            " [ 34]\n",
            " [ 17]\n",
            " [ 76]\n",
            " [ 37]\n",
            " [ 77]\n",
            " [ 95]\n",
            " [ 68]\n",
            " [ 19]\n",
            " [ 60]\n",
            " [ 72]\n",
            " [  3]\n",
            " [ 53]\n",
            " [ 51]\n",
            " [ 62]\n",
            " [ 67]\n",
            " [ 39]\n",
            " [ 46]\n",
            " [ 74]\n",
            " [ 64]\n",
            " [ 79]\n",
            " [ 65]], shape=(250, 1), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Passer le tableau dans notre sequence \"caractere_par_index\"\n",
        "# Pour ca, je dois le reformater\n",
        "echantillon_indices = tf.squeeze(echantillon_indices, axis=1).numpy()\n",
        "\n",
        "echantillon_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmGmV6WofBRY",
        "outputId": "fbe0ebcb-f6bb-487b-b97b-cf1800cf8279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 75,   6,  51,  83,  62,  98,  79, 100,  35,  33,  10,  20,  21,\n",
              "         3,  73,  74, 102, 103, 103,  73,  69,  18,  79, 100, 100,  70,\n",
              "        74,  20,  90,  48,  55,  39,  29,  94,   1,  63, 102,  74,  51,\n",
              "         0,  68,  39,  36,  96,  47,  62,  78,  49,  31,  12,  34, 100,\n",
              "        66,  38,  31,   0,  11,  16,  19,  31,  40,  50,  17,  33,  16,\n",
              "        13,  38,  89,   2,  71,  51,  36,  19,  17,  74,  51,  83,  34,\n",
              "        26,  23,   0,  10,  51,  62,  86,  96,  12,  36,  62,  42,  35,\n",
              "        70,  66,  93,  22,  21,  38,  66,  30,  20,  50,  87,  75,  21,\n",
              "        51,  77,  53,  87,  24,  94,  51,  12,  31,  76,  87,  94,  88,\n",
              "        40, 100,  53,  70,  60,  55,  98,  42,  33,  33,  76,  85,  89,\n",
              "        47,  73,   4,  25,  85,   2,  99,  73,  44,  31,  46,  66,  45,\n",
              "        61,  16,  16,   4,  81,  95,  47,   7,  80,  26,  59,  40,  53,\n",
              "        40,  99,  29,  82,   0,  23,  47,  71,   0, 103,  57,  30,  36,\n",
              "        54,  32,  23,  80,  12,  30,   4,  63,  38,  70,  15,  88, 100,\n",
              "        40,  38,  29,  64,  27,  92,  14,  83,  34,  61,  87,  30,  98,\n",
              "        41,  40,   1,  98,   6,  65,  33,  86,  84,  42,  75,  60,   1,\n",
              "        69,  89,  62,  65,  91,  69,  54,  49,   1,  65,  13,  95,  12,\n",
              "        50,  37,  45,  97,  10,  64,  64,  33,  34,  17,  76,  37,  77,\n",
              "        95,  68,  19,  60,  72,   3,  53,  51,  62,  67,  39,  46,  74,\n",
              "        64,  79,  65])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# passer mon echantillon en index_par_caractere\n",
        "index_par_caractere[echantillon_indices]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SludQjNaffGr",
        "outputId": "cf867040-82b5-469c-e8a2-843b37203571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['x', ')', '_', 'Â', 'k', 'ï', '°', 'ô', 'K', 'I', '.', '8', '9',\n",
              "       '\"', 'v', 'w', 'ù', 'û', 'û', 'v', 'r', '6', '°', 'ô', 'ô', 's',\n",
              "       'w', '8', 'â', 'X', 'd', 'O', 'E', 'é', ' ', 'l', 'ù', 'w', '_',\n",
              "       '\\n', 'q', 'O', 'L', 'ë', 'W', 'k', '«', 'Y', 'G', '0', 'J', 'ô',\n",
              "       'o', 'N', 'G', '\\n', '/', '4', '7', 'G', 'P', 'Z', '5', 'I', '4',\n",
              "       '1', 'N', 'à', '!', 't', '_', 'L', '7', '5', 'w', '_', 'Â', 'J',\n",
              "       'B', ';', '\\n', '.', '_', 'k', 'É', 'ë', '0', 'L', 'k', 'R', 'K',\n",
              "       's', 'o', 'è', ':', '9', 'N', 'o', 'F', '8', 'Z', 'Ê', 'x', '9',\n",
              "       '_', 'z', 'b', 'Ê', '?', 'é', '_', '0', 'G', 'y', 'Ê', 'é', 'Ô',\n",
              "       'P', 'ô', 'b', 's', 'i', 'd', 'ï', 'R', 'I', 'I', 'y', 'È', 'à',\n",
              "       'W', 'v', \"'\", 'A', 'È', '!', 'ñ', 'v', 'T', 'G', 'V', 'o', 'U',\n",
              "       'j', '4', '4', \"'\", '»', 'ê', 'W', '*', 'º', 'B', 'h', 'P', 'b',\n",
              "       'P', 'ñ', 'E', 'À', '\\n', ';', 'W', 't', '\\n', 'û', 'f', 'F', 'L',\n",
              "       'c', 'H', ';', 'º', '0', 'F', \"'\", 'l', 'N', 's', '3', 'Ô', 'ô',\n",
              "       'P', 'N', 'E', 'm', 'C', 'ç', '2', 'Â', 'J', 'j', 'Ê', 'F', 'ï',\n",
              "       'Q', 'P', ' ', 'ï', ')', 'n', 'I', 'É', 'Ç', 'R', 'x', 'i', ' ',\n",
              "       'r', 'à', 'k', 'n', 'æ', 'r', 'c', 'Y', ' ', 'n', '1', 'ê', '0',\n",
              "       'Z', 'M', 'U', 'î', '.', 'm', 'm', 'I', 'J', '5', 'y', 'M', 'z',\n",
              "       'ê', 'q', '7', 'i', 'u', '\"', 'b', '_', 'k', 'p', 'O', 'V', 'w',\n",
              "       'm', '°', 'n'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrainement"
      ],
      "metadata": {
        "id": "addJRn2of5fV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Il faut un nbre réaliste , sur un modele type génération de texte\n",
        "## je ne devrais pâs etre en dessous de minimum 30 epochs\n",
        "epochs = 25"
      ],
      "metadata": {
        "id": "SptYkvoEgAGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modele.fit(dataset, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sv1oBTq7ghjO",
        "outputId": "e29eb789-b03b-41fa-ff8f-ba3091fd79db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "76/76 [==============================] - 30s 348ms/step - loss: 3.1349\n",
            "Epoch 2/25\n",
            "76/76 [==============================] - 25s 320ms/step - loss: 2.3656\n",
            "Epoch 3/25\n",
            "76/76 [==============================] - 24s 305ms/step - loss: 2.1766\n",
            "Epoch 4/25\n",
            "76/76 [==============================] - 26s 331ms/step - loss: 2.0110\n",
            "Epoch 5/25\n",
            "76/76 [==============================] - 24s 310ms/step - loss: 1.8552\n",
            "Epoch 6/25\n",
            "76/76 [==============================] - 23s 303ms/step - loss: 1.7162\n",
            "Epoch 7/25\n",
            "76/76 [==============================] - 25s 327ms/step - loss: 1.5998\n",
            "Epoch 8/25\n",
            "76/76 [==============================] - 24s 315ms/step - loss: 1.5072\n",
            "Epoch 9/25\n",
            "76/76 [==============================] - 23s 301ms/step - loss: 1.4326\n",
            "Epoch 10/25\n",
            "76/76 [==============================] - 25s 328ms/step - loss: 1.3761\n",
            "Epoch 11/25\n",
            "76/76 [==============================] - 24s 310ms/step - loss: 1.3292\n",
            "Epoch 12/25\n",
            "76/76 [==============================] - 25s 318ms/step - loss: 1.2923\n",
            "Epoch 13/25\n",
            "76/76 [==============================] - 25s 326ms/step - loss: 1.2612\n",
            "Epoch 14/25\n",
            "76/76 [==============================] - 24s 304ms/step - loss: 1.2349\n",
            "Epoch 15/25\n",
            "76/76 [==============================] - 25s 329ms/step - loss: 1.2108\n",
            "Epoch 16/25\n",
            "76/76 [==============================] - 24s 312ms/step - loss: 1.1902\n",
            "Epoch 17/25\n",
            "76/76 [==============================] - 23s 304ms/step - loss: 1.1720\n",
            "Epoch 18/25\n",
            "76/76 [==============================] - 24s 312ms/step - loss: 1.1537\n",
            "Epoch 19/25\n",
            "76/76 [==============================] - 24s 317ms/step - loss: 1.1365\n",
            "Epoch 20/25\n",
            "76/76 [==============================] - 25s 318ms/step - loss: 1.1206\n",
            "Epoch 21/25\n",
            "76/76 [==============================] - 24s 313ms/step - loss: 1.1055\n",
            "Epoch 22/25\n",
            "76/76 [==============================] - 25s 323ms/step - loss: 1.0897\n",
            "Epoch 23/25\n",
            "76/76 [==============================] - 24s 308ms/step - loss: 1.0749\n",
            "Epoch 24/25\n",
            "76/76 [==============================] - 24s 307ms/step - loss: 1.0607\n",
            "Epoch 25/25\n",
            "76/76 [==============================] - 24s 317ms/step - loss: 1.0460\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f245c2f02b0>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sauvegarde du modele\n",
        "modele.save(\"/content/LesMiserables.h5\")"
      ],
      "metadata": {
        "id": "QOx86RMAiVvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prédiction - Génération de texte"
      ],
      "metadata": {
        "id": "ngBRn2hoUDxx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ajuster la taille du batch de 128 et le passer à 1"
      ],
      "metadata": {
        "id": "26SXNvGXUR37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import rnn\n",
        "# on va crer un nouveau modele\n",
        "modele = create_modele(vocabulaire_size, embed_dimension, rnn_neurones, taille_batch=1)\n",
        "# On charge les poids du modele sauvegardé\n",
        "modele.load_weights('LesMiserables.h5')\n",
        "# construction avec forme d'entrée Tensorshape de 1 par none\n",
        "modele.build(tf.TensorShape([1, None]))\n",
        "\n",
        "# Résumé de ce nouveau modele\n",
        "modele.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-SSI1bYUWx6",
        "outputId": "64492749-6ddb-4c3a-f599-0ba5c45ce94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (1, None, 85)             8925      \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (1, None, 1026)           3425814   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (1, None, 105)            107835    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,542,574\n",
            "Trainable params: 3,542,574\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fonction pour la génération de texte"
      ],
      "metadata": {
        "id": "h1VZEVS6VwBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction_texte(modele, start_seed, gen_size=500, temp=0.3):\n",
        "  nb_caracteres_generes = gen_size\n",
        "  # on vectorise le texte du seed de depart\n",
        "  # on va devoir le transformer en caractere par index\n",
        "  input_seed = [caractere_par_index[s] for s in start_seed]\n",
        "  # on etend les dimensions pour correspondre au format batch\n",
        "  input_seed = tf.expand_dims(input_seed, 0)\n",
        "\n",
        "  # on créer notre liste vide qui contiendra notre resultat\n",
        "  texte_predit = []\n",
        "  # On peut lui donner une temperature\n",
        "  temperature = temp\n",
        "\n",
        "  # on remet à zéro l'état du modele\n",
        "  modele.reset_states()\n",
        "\n",
        "  # et on boucle sur le nbre de caracteres souhaités\n",
        "  for i in range(nb_caracteres_generes):\n",
        "    # on génère des prédictions\n",
        "    predictions = modele(input_seed)\n",
        "    # on supprime la forme du batch\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "    # on utilise une distribution catégorielle pour selectionner le caractère suivant\n",
        "    predictions = predictions / temperature\n",
        "    # puis l'index predit en lui passant les predictions et le nb d'echantillons\n",
        "    # on va aussi faire un peu d'indexage pour avoir uniquement notre index\n",
        "    prediction_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    # on passe le caractere predit pour la prochaine entrée (un pas en avant)\n",
        "    input_seed = tf.expand_dims([prediction_id], 0)\n",
        "\n",
        "    # on retransforme d'index par caractere\n",
        "    texte_predit.append(index_par_caractere[prediction_id])\n",
        "\n",
        "  # on retourne le start seed correspondant au mot de départ, en joignant le texte predit\n",
        "  # à la suite\n",
        "  return (start_seed+''.join(texte_predit))\n"
      ],
      "metadata": {
        "id": "9KxM8vHoVzZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### faire une generation"
      ],
      "metadata": {
        "id": "c833HH6LdGyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction_texte(modele, \"Je suis sortie de la maison de bonne heure\", gen_size=1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0cblSlsdGGe",
        "outputId": "be5ce896-4053-4c3e-a169-9e5e06b418ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Je suis sortie de la maison de bonne heure, il avait\n",
            "conservé les propriétaires de l'épouvante, les passants voyaient des ressources, et\n",
            "de l'autre le point de vue de la foule et d'abord contre le mur\n",
            "de cette maison de la rue de l'Homme-Armé.\n",
            "\n",
            "--Je ne vous passerai pas.\n",
            "\n",
            "--Et les petits conseils de l'événement des petits conseils de conseil de ce\n",
            "mot d'ordre se remit à marcher dans le coeur des passants. Il\n",
            "se retourna et dit:\n",
            "\n",
            "--Vous êtes parti tout ce qui s'appelle la barricade!\n",
            "\n",
            "Cependant il s'appelait Marius qui s'était mis à lui dire:\n",
            "\n",
            "--Vous m'avez donc pas moins que le coeur de ce monde et la misère. Le\n",
            "progrès n'avait pas dit qu'il n'avait pas de chose qu'un poteau pour le\n",
            "salut de la contre-coup de police de l'éléphant.\n",
            "\n",
            "Le prisonnier ne pouvait se retourner dans les proclamations de l'argot\n",
            "de l'homme qui avait laissé de se dire qu'il avait apporté un homme qui\n",
            "s'était posé sur le boulevard de la rue de la Chanvrerie, et le soleil s'appelle trois mois\n",
            "aux passants de l'émeute, le vieillard s'approcha de l'autre côté\n"
          ]
        }
      ]
    }
  ]
}